{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan_lu/miniconda3/envs/mistral/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/jonathan_lu/miniconda3/envs/mistral/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    }
   ],
   "source": [
    "from mistral_inference.transformer import Transformer\n",
    "\n",
    "model = Transformer.from_folder(\"/home/shared_models/huggingface/mistralai/Mistral-Nemo-Instruct-2407\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    }
   ],
   "source": [
    "# Import needed packages:\n",
    "from mistral_common.protocol.instruct.messages import (\n",
    "    UserMessage,\n",
    "    ToolMessage,\n",
    "    FinetuningAssistantMessage\n",
    ")\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "from mistral_common.protocol.instruct.tool_calls import (\n",
    "    Function,\n",
    "    Tool,\n",
    "    ToolCall,\n",
    "    FunctionCall\n",
    ")\n",
    "from mistral_common.protocol.instruct.validator import (\n",
    "    ValidationMode,\n",
    ")\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "\n",
    "# Load Mistral tokenizer\n",
    "\n",
    "model_name = \"mistral-nemo\"\n",
    "\n",
    "tokenizer = MistralTokenizer.from_file(str(MistralTokenizer._data_path() / \"tekken_240718.json\"), mode=ValidationMode.finetuning)\n",
    "\n",
    "# Tokenize a list of messages\n",
    "tokenized = tokenizer.encode_chat_completion(\n",
    "    ChatCompletionRequest(\n",
    "        tools=[\n",
    "            Tool(\n",
    "                function=Function(\n",
    "                    name=\"get_current_weather\",\n",
    "                    description=\"Get the current weather\",\n",
    "                    parameters={\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                            },\n",
    "                            \"format\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                                \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\"location\", \"format\"],\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "        messages=[\n",
    "            SystemMessage(content=\"this is a system message\"),\n",
    "            UserMessage(content=\"What's the weather like today in Paris\"),\n",
    "            FinetuningAssistantMessage(content=\"Let me search that up for you\"),\n",
    "            FinetuningAssistantMessage(tool_calls=[ToolCall(id=\"3XhQnxLsT\", function=FunctionCall(name=\"get_current_weather\", arguments='{\"location\": \"Paris, FR\", \"format\": \"celsius\"}'))]),\n",
    "            ToolMessage(tool_call_id=\"3XhQnxLsT\", content=\"20\"),\n",
    "            FinetuningAssistantMessage(content=\"The weather is 20 degrees Celsius\"),\n",
    "            UserMessage(content=\"Describe what that temperature feels like\"),\n",
    "            FinetuningAssistantMessage(content=\"It feels warm\"),\n",
    "        ],\n",
    "        model=model_name,\n",
    "    )\n",
    ")\n",
    "tokens, text = tokenized.tokens, tokenized.text\n",
    "\n",
    "# Count the number of tokens\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST]What's the weather like today in Paris[/INST]Let me search that up for you[TOOL_CALLS][{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"Paris, FR\", \"format\": \"celsius\"}, \"id\": \"3XhQnxLsT\"}]</s>[TOOL_RESULTS]{\"content\": 20, \"call_id\": \"3XhQnxLsT\"}[/TOOL_RESULTS]The weather is 20 degrees Celsius</s>[AVAILABLE_TOOLS][{\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\", \"description\": \"Get the current weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}, \"format\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"The temperature unit to use. Infer this from the users location.\"}}, \"required\": [\"location\", \"format\"]}}}][/AVAILABLE_TOOLS][INST]Describe what that temperature feels like[/INST]It feels warm</s>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to know the forecast for the next few days?\n"
     ]
    }
   ],
   "source": [
    "from mistral_inference.generate import generate\n",
    "\n",
    "out_tokens, _ = generate([tokens], model, max_tokens=1024, temperature=0.35, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
    "result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
